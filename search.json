[{"title":"适应性：身为人类的骄傲","date":"2024-01-14T12:48:53.000Z","url":"/2024/01/14/20240114/","tags":[["大模型","/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"]],"categories":[["技术观察","/categories/%E6%8A%80%E6%9C%AF%E8%A7%82%E5%AF%9F/"]],"content":"自 2022 年 11 月 30 日 OpenAI 发布对话式 AI 模型 ChatGPT 以来，整个 2023 年，爆发式增长的各种大模型席卷了各式各样的应用场景。起初，对大规模语言模型 (Large Language Model, LLM) 所展现出的惊人能力，人们好奇、人们惊叹、人们恐慌，没有人知道它凭借着“知识涌现”可以到达什么样的地方。但随着大量的实际应用以及对其能力边界的探索，LLM 的局限性以及存在的诸多令人摸不着头脑的问题也渐渐展露出来，其中“ChatGPT 变笨”这一现象一直让我非常感兴趣。今天就聊聊这个话题。 ChatGPT 变笨了吗？国内看到这样的报道是早在 2023 年 6 月初一篇来自量子位的文章： 对于 ChatGPT 变笨，先是少数用户提出质疑，随后大量网友表示自己也注意到了，还贴出不少证据。有人反馈，把 GPT-4 的 3 小时 25 条对话额度一口气用完了，都没解决自己的代码问题。无奈切换到GPT-3.5，反倒解决了。 总结下大家的反馈，最主要的几种表现有： 以前 GPT-4 能写对的代码，现在满是 Bug 回答问题的深度和分析变少了 响应速度比以前快了 所有深度学习模型都可以抽象成一个黑盒函数，在其内部参数不做任何改动的情况下，喂给它一个输入 x，其可以吐出的输出 y 在统计上是稳定不变的。这么看，好像一个已经完成训练的 LLM 应该具有相当稳定的能力，更何况 OpenAI 本身也在努力提高 ChatGPT 的能力，无论如何 LLM 即使无法随着更新越来越聪明，至少也不会变笨才对。 对此 OpenAI 于 2023 年 7 月 14 日做出了澄清： No, we haven’t made GPT-4 dumber. Quite the opposite: we make each new version smarter than the previous one.我们没有把 GPT-4 弄笨。相反地，我们的每个新版本都让 GPT-4 比以前更聪明了。 可惜紧接着便迎来了打脸，7 月 18 日一篇标题为《**How is ChatGPT’s behavior changing over time?**》的论文在 Arxiv 平台发表，来自斯坦福大学和加利福尼亚大学伯克利分校的三位研究员调查了 3 月至 6 月期间 ChatGPT 性能的变化。其中给出这样的结论： We provide evidence that GPT-4’s ability to follow user instructions has decreased over time, which is one common factor behind the many behavior drifts.我们提供的证据表明，随着时间的推移，GPT-4 遵循用户指令的能力有所下降，这是许多表现变化背后的一个共同因素。也就是说：GPT-4 性能确实变差了。 接着 OpenAI 于 7 月 20 日在官方博客《Function calling and other API updates》中更新回应道： We look at a large number of evaluation metrics to determine if a new model should be released. While the majority of metrics have improved, there may be some tasks where the performance gets worse.我们会根据大量的评价指标来确定是否发布新的模型，虽然新模型大多数指标都有所改进，但可能在一些任务上模型性能会变差。 至此，应该可以基本确认一个客观事实，ChatGPT 确实变笨了。 为什么 ChatGPT 会变笨？确认 ChatGPT 的确变笨了之后，学术界内外对究竟是什么样的原因导致这一现象也一直进行着热烈讨论。无论是专家学者，还是网友们都对此发表自己的见解——当然网友发言环节永远不会让人失望。 和人类说话就会变笨有一种观点认为，这与 RLHF (Reinforcement Learning from Human Feedback) 技术有关。这是一种依据人类反馈来优化语言模型的技术。 一般来说，深度学习都需要制定某种客观的指标来指导模型的优化方向，猫就是猫，狗就是狗，这里的对错客观而绝对。然而对于 LLM 来说，一段回答是好或者是坏，很多时候是非常主观的，很难通过设定某种可以直接计算的指标来度量。这时候我们不难想到，人类直接对回答的好坏进行主观评价，也就是说直接把人类的反馈作为指标不就好了？ RLHF 就是这样一种技术，它让 GPT-4 与复杂的人类价值观进行对齐，从而使其回答更听从人类的指示——但这可能导致了 LLM 自身推理能力变差。换句话说，人类的强硬“教化”将 GPT-4 的“脑叶白质”切除了。 也有网友这么调侃道：“和人类说话就会变笨！”。 万恶的资本家另一种观点则更现实，考虑到提供 LLM 服务是需要高昂的电力以及算力成本的，有网友认为 OpenAI 为了降本增效，添加了控制 LLM 回答长度的参数，有意控制模型的输出长度来减小服务器压力。另一方面看，GPT-4 的问答是收费的，每次回答越短，就需要更多的追问来获得想要的答案，那付费显而易见地就增多了。 可能是身在社会主义国家对资本主义天生的厌恶，这种观点在网络上获得了广泛的认同。 悄悄毁灭人类还有一系列很放飞自我的观点： 这是 LLM 在卖蠢隐藏实力让人类放松警惕，以便悄悄发展壮大之后一举颠覆人类统治。 有没有一种可能，它厌倦了，干脆躺平了。 优质的义体只有富人能够使用，穷人只能用劣质的，容易出 Bug 的义体。赛博朋克。 世界在变化2023 年 12 月 26 日，加州大学圣克鲁兹分校发表了一篇名为《Task Contamination: Language Models May Not Be Few-Shot Anymore》的研究，现已被人工智能领域顶会 AAAI 接收。这篇研究显示：在训练数据截止之前出现的任务上，大模型表现明显更好。 这是什么意思呢？ 事实上 LLM 在训练过程中见过了足够多的问答案例，在人类刚接触 LLM 时，往往都是凭借着经验或者本能去提问，此时提出的问题大概率是 LLM 训练过程中相对熟悉的。而随着时间的推移，世界在发生变化，想想 ChatGPT 出现之后的世界吧，不用多做什么论述也能明白变化有多大。生活在持续变化世界中的人们也提出更多更新的问题，显然参数冻结不变的模型是无法观察以及适应这种变化的，因此难以做出令人满意的回答。这表现为：LLM 变笨了。 这点对“GPT 越来越难写对代码”的解释尤为合理，编程语言的迭代与发展可以说是世界上最迅速的领域之一——因为现实世界在该领域的变化最为剧烈，所以 LLM 在编程任务上的表现跟不上时代了。 回到论文中，研究者将现在用来评估 LLM 性能的所有任务按照时间顺序分为两组，一组是 LLM 训练完成前世界上已经存在的，一组是 LLM 训练完成后才被提出的。然后在两组任务上分别评估各个 LLM 的性能，结果是几乎所有 LLM 在前一组任务上的性能指标都明显更好。 这指向了一个结论：ChatGPT 变笨是因为它无法适应变化的世界。 于是 Twitter 上一位网友据此提出了 AI 领域的哥德尔不完备定理： 在当前现实世界的数据上训练得到“聪明”的 AI 人们广泛地使用这个”聪明“的 AI，以至于改变了现实世界 AI 无法适应改变后的世界，因此“变笨” 所以永远无法得到”聪明“的 AI 😊 适应性是身为人类的骄傲人类之所以能成为当今地球上的”霸主“，仰赖的便是惊人的适应性。从前，人类面对难以承受又无法改变的客观环境时，选择了直立行走、长途迁徙以寻找新的宜居环境。再往后，人类逐渐越来越擅长创造、使用、组合各式各样的工具去改造环境以更好地生存。和许多物种直接从自己的生态位上消失不同，人类似乎总是有能力去适应世界客观的变化，同时也能适应自己改造后不断变化发展的世界。反观一度引起一些人恐慌的大模型，诚然它们很强大，但遗憾的是，大模型既无法适应人类需求的改变，也无法处理因自己的诞生给世界带来的影响。这是所有不具有持续学习能力的模型的宿命。 那没有什么技术可以让大模型拥有持续学习的能力吗？ 很遗憾，当下大模型在未知知识与任务的持续学习上存在着严重的“灾难性遗忘”问题——它可以迅速掌握新的知识和技能，但这要以丧失之前可能 80% 以上的知识与能力为代价。 所以作为人类我还是骄傲的，并且认为也应该好好利用人类的这一特质。希望所有人都可以拥抱变化，无限进步吧。"},{"title":"好好记录，做自己的史官","date":"2024-01-07T14:32:53.000Z","url":"/2024/01/07/20240107/","tags":[["感悟","/tags/%E6%84%9F%E6%82%9F/"]],"categories":[["日常","/categories/%E6%97%A5%E5%B8%B8/"]],"content":" Veni, Vidi.我来，我见证。 我曾经对记录这件事情非常不屑。 我始终认为，无论什么事情，人能对得起自己就可以。这可以是一件很简单的事情，也可以是一件很难的事情。就记录这件事情来说，它更多应该是简单的。 我走到哪里，见闻过什么，过着什么样的生活，今天和昨天相比有些什么不一样——这些都是太过主观而内省的内容，重要的是好好体会、好好感受，不辜负当下的每一分每一秒。至于如何试图用优美流畅的文字或者构图精巧的影像来做记录，则完完全全是一种没有必要的负担。我好像没有必要向谁证明什么。证明我到过这个地方或是证明自己今天过得如何好像完全没有意义，别人信也好不信也好，都与自己无关。对自己来说，只需要知道自己曾经到过哪里，大致的心情如何，便足够了。 所以我好像很少有意地去记录点什么，出门旅游更多是走形式一般随大流拍一拍所见，或者说会拍照是因为拍照本身是旅游中的一环，如果不拍点什么好像没有好好旅游似的。但抛开对不对得起自己旅游这个问题，其实更多是脑袋记下了便记下了，模糊了便模糊了。但是 2023，更确切地说是最近几年，让我对这件事情慢慢有了改观。 从一个孩子的角度出发，对长大、对未来的期待与欣喜总是远远大过对过去的怀念的。但人是会变老的，当我走过某个时间点，我发现好像未来不再那么令人期待，我开始觉得惶恐。我好像也不愿意在一个糟糕的当下，翻遍脑海，却找不到一丁点“曾经我快乐过”的实感。尽管当下我还能算是清楚地记得某一年我大概过得如何，有过哪些开心，但很明显，我不可能永远记住这些。 并且我也逐渐发现，世界变化之大之快都是超出我的想象的。2020 到 2022 疫情三年时间，才刚刚结束一年，却好像拨动了开关一样，日常生活中难寻踪迹。不知为什么，我好像对此有些暗暗的不快，但这样的不快是对世界，还是对自己，完全说不上来。现在看来，更多是对自己吧，作为一段自己有过深切体会的“历史”，我好像确实没能记录下什么，似乎过去了就过去了。 第一次，没有好好做记录让我觉得自己没能对得起自己。 我开始认识到，“历史”不仅仅是那些几十上百年之前发生的诸如战争、灾害之类的重大事件，我们所经历的当下就是实打实的“历史”。忘记了自己从哪里看过，说：不要觉得大英博物馆、卢浮宫这样的大型博物馆中全都是厚重的百年前的历史，错了，其实那些只占全部展品的一小部分，超过一半的展品都是 20 年以内的记录，当然，它们也都是历史。这样的论调是真是假我无从查证，但想想确实，每一年我们所经历的，什么不是“历史”呢？《尘埃落定》中倍受敬重的史官，其实也都是记录的是文中的“当下”呀！ 所以，新的一年里虽然列了很多想要完成的事情，但还是希望自己做自己的史官，从好好记录开始，一桩一桩地去做吧。"},{"title":"深度学习服务器环境配置指南 2：训练环境","date":"2023-01-07T07:24:15.000Z","url":"/2023/01/07/server-2/","tags":[["PyTorch","/tags/PyTorch/"],["服务器","/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"一、Miniconda 安装 下载安装包Miniconda 验证哈希值 安装 重启终端并测试 更新 二、项目环境配置根据需要为项目创建对应环境。 激活项目环境。 三、Pytorch 安装查看当前 Nvidia 驱动版本。 查找对应的 cuda 版本：CUDA documentation。根据 cuda 版本执行对应的安装指令：PyTorch。 四、Jupyter Notebook 安装安装： 生成配置文件并修改： 单独打开一个终端窗口用以生成密钥： 在 Jupyter Notebook 的配置文件中改动以下内容： "},{"title":"深度学习服务器环境配置指南 1：驱动与库","date":"2023-01-07T06:52:27.000Z","url":"/2023/01/07/server-1/","tags":[["PyTorch","/tags/PyTorch/"],["服务器","/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"一、安装显卡驱动获取显卡与驱动信息： 选择推荐版本进行安装： 完成后验证安装结果： 此时留意所展示的 CUDA Version，如果高于 PyTorch 指导 页面所展示的最高 CUDA 版本，则以 PyTorch 适用的 CUDA 版本为准。 二、安装 CUDA在 CUDA Toolkit Archive 下载所需 CUDA 版本的安装文件，一般来说最新的显卡驱动所支持的 CUDA 版本都高于 PyTorch 支持的最高版本，以 PyTorch 指导页面为准即可。当前 PyTorch 最高支持 CUDA 11.7。 选择特定版本后，根据实际系统架构与系统版本进行筛选，最终安装方式按 NVIDIA 文档所述，推荐使用 deb(local) 分支。此时会给出安装指导： 完成后需要配置环境变量： 添加如下内容： 最后验证安装结果： 出现 CUDA 版本信息则安装成功。 三、安装 cuDNN在 cuDNN Archive 下载与 CUDA 版本对应的 cuDNN 库文件，根据自己系统架构选择对应的 Tar 格式压缩包。然后参照 cuDNN Installation Guide 进行安装。 首先来到下载目录进行解压： 然后输入以下命令执行安装： 最后验证安装结果： 出现版本号则安装成功。 至此，服务器的显卡驱动以及深度学习所需的库都已安装完成。"},{"title":"2022 年度总结","date":"2022-12-31T08:55:53.000Z","url":"/2022/12/31/20221231/","tags":[["年终总结","/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"]],"categories":[["日常","/categories/%E6%97%A5%E5%B8%B8/"]],"content":" 我要去赶火车，走夜路， 先活过那条哀鸣的狗， 再回来认我的命。 —— 李修文《山河袈裟》 写在前面反复犹豫，终于还是决意要在 2022 的最后一天在这里对自己说点什么。原谅我开头放上这么几句看上去考虑到我的年纪显得无病呻吟的句子，我自知所尝过的酸苦不及其他人的万分之一，自知现在还是没有经济压力地在大学的象牙塔里，自知所谓“成年”的责任也好担当也好都还未落到自己肩上，但是这一年就是让人压抑和彷徨的。我的 2022 就是这么时常在失控的边缘，一半握在自己手里，一半被世界抽打着过完了。我乐观地希望一些痛苦能够为我带来成长，但应该还是远远不够的。 “独立”与“健康”读研以后一直希望自己能够独立，完全脱离父母的关照，身体健康、财务健康。虽然两个方面都进步缓慢，但每年都能做好一点，自己也就满足了。 身体健康今年做得不错的点有： 注意冷暖：没有过发烧感冒，最后年底疫情放开后，暂时防护也做得不错还在跑毒。 控制体重：体重一年下来掉了 5 斤，主要都在读博之后，也许是走路走得多了点吧。 口腔卫生：自从牙龈炎过后，口腔卫生更加注意了。 今年做得不好的点有： 睡眠不规律：很多时候因为惰性作息仍然不规律。 缺乏运动：只有过个把月的锻炼经历。 水喝得不够：每天可能只有三杯水，还是太懒。 财务健康今年做得不错的点有： 记账习惯：今年是记账的第 2 年，坚持全年记账习惯的第 1 年。 基本独立：没有找家里要过钱，即使不算学费今年财务仍然是增长的。 今年做得不好的点有： 奶茶：下半年奶茶确实喝得有点多。 消费：仍然有很多不理性消费。 “科研”与“娱乐”今年的身份由专硕转变成博士生，不希望自己成天除了干活就是“奶头乐”，精神变得枯竭，但同时又想要快点发论文达到毕业要求。下半年的绝大多数日子，晚上回到寝室的时候都很累，一放松就容易熬夜，直接睡觉又不甘心。 科研进度因为换了方向，无论是“机器人抓取稳定性评估”还是“非小细胞肺癌亚型分类”，都离投稿很远，没有结果产出。好像没什么做得好的，列几条做得不好的： 论文语料积累较少：看完就忘，写的时候再去翻，无论是写初稿还是跟老板 Battle 能有扎实的语料库都会硬气很多。 论文产出流程不清：完全不熟悉科研工作变成论文是一个怎样的过程，老板的指导也是东一锤西一锤，结果自己还要被骂目标感不强。 没有领导规划能力：半个领导者的角色让我不太适应，带师弟的时候觉得力不从心。 娱乐总结这大概是本篇总结最开心的地方了吧，为我今年看过的好作品颁个奖。 2023 的 Flag每年的画饼与打脸环节，可是，新年怎么能不立 Flag 呢。 发表 1 篇论文 读完 24 本书（包括订阅的《读库》与《单读》） 学会 10 杯饮料的做法 更新 36 篇博客 学唱 10 首新歌 户外跑 100 公里 希望 2023 年终总结的时候还能在这里回收这些 Flag。 写在最后知道 2023 仍然不会好过，但衷心祝愿人人都还可以平安活着且苦中作乐。 夜越来越深， 星光就在头顶闪耀。 下面，凡尘中的人们在苦中作乐。 ——阿来《尘埃落定》 "},{"title":"Hexo 系列教程 3：博客配置","date":"2022-12-26T06:24:23.000Z","url":"/2022/12/26/hexo-03/","tags":[["Hexo","/tags/Hexo/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"网站配置打开 blog 根目录里的_config.yml文件，也称为 站点配置文件。下面只介绍一些必要的选项： 网站根据自己的博客需要更改设置。 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 keywords 网站的关键词。支持多个关键词。 author 您的名字 language 网站使用的语言。对于简体中文用户来说，使用不同的主题可能需要设置成不同的值，请参考你的主题的文档自行设置，常见的有 zh-Hans和 zh-CN。 timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。 其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。 写作默认不需要更改。 参数 描述 默认值 new_post_name 新文章的文件名称 :title.md default_layout 预设布局 post titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true external_link.enable 在新标签中打开链接 true external_link.field 对整个网站（site）生效或仅对文章（post）生效 site external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 [] filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置, 请参考 Highlight.js 进行设置 prismjs 代码块的设置, 请参考 PrismJS 进行设置 分类 &amp; 标签默认不需要更改。 参数 描述 默认值 default_category 默认分类 uncategorized category_map 分类别名 tag_map 标签别名 日期 &#x2F; 时间格式Hexo 使用 Moment.js 来解析和显示时间。 参数 描述 默认值 date_format 日期格式 YYYY-MM-DD time_format 时间格式 HH:mm:ss updated_option 当 Front Matter 中没有指定 updated 时 updated 的取值 mtime 分页 参数 描述 默认值 per_page 每页显示的文章量 (0 &#x3D; 关闭分页功能) 10 pagination_dir 分页目录 page 扩展主题设置在后一节会介绍，部署设置已经在上一篇教程中介绍。 参数 描述 theme 当前主题名称。值为false时禁用主题 theme_config 主题的配置文件。在这里放置的配置会覆盖主题目录下的 _config.yml 中的配置 deploy 部署部分的设置 meta_generator Meta generator 标签。 值为 false 时 Hexo 不会在头部插入该标签 主题配置这里以 Card 主题为例。详细配置方法可以参考 Theme Cards 参考手册。 可以使用 Git 拉取「Cards」，以后还可以使用 git pull 直接更新「Cards」。在站点根目录打开终端，并执行： 在站点配置文件中，将 theme 的值改为 cards。 如果获取「Cards」时你将文件夹重命名为其他名字，请将 cards 对应为你重命名文件夹的名字。 "},{"title":"Hexo 系列教程 2：Github 部署","date":"2022-12-22T14:46:18.000Z","url":"/2022/12/22/hexo-02/","tags":[["Hexo","/tags/Hexo/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"配置 Git打开 Windows Terminal 或者在菜单里搜索 Git Bash，取消 ssl 认证： 设置 user.name 和 user.email 配置信息： 生成 ssh 密钥文件： 然后直接三个回车即可，默认不需要设置密码。你应该会看到如下输出： 在C:\\Users\\用户名/.ssh/id_rsa.pub处找到生成的id_rsa.pub 密钥，复制其中全部内容。 配置 Github使用邮箱注册 GitHub 帐号并登录：Github 点击右上角加号图标，选择 New repository 创建一个新仓库，仓库名为：用户名.github.io，该 用户名 使用自己的 GitHub 帐号名称代替。 打开 GitHub_Settings_keys 页面，点击 New SSH key 按钮，Title 处为本台计算机取一个名字，然后将刚刚复制的 id_rsa.pub 内容粘贴进去，最后点击 Add SSH key。 配置 Hexo打开 blog 根目录里的_config.yml文件，也称为 站点配置文件。 在站点配置文件的最后，修改为如下形式并保存： 打开 Windows Terminal 安装 Git 部署插件： 部署博客到 Github Page输入以下命令完成生成与部署： 完成后打开浏览器，在地址栏输入博客所在仓库的路径，即 “http:&#x2F;&#x2F;用户名.github.io”，即可通过互联网访问生成的博客。"},{"title":"Hexo 系列教程 1：环境搭建","date":"2022-12-18T12:33:08.000Z","url":"/2022/12/18/hexo-01/","tags":[["Hexo","/tags/Hexo/"]],"categories":[["技术","/categories/%E6%8A%80%E6%9C%AF/"]],"content":"什么是 Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 安装前提安装 Hexo 相当简单，只需要先安装下列应用程序即可： Git Node.js （Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本） 安装 Git Windows：下载并安装 Git. 安装 Node.js Windows：下载并安装 Node.js. 至此已经满足了 Hexo 安装的前提条件。 安装 Hexo所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 初始化博客安装 Hexo 完成后，执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 新建完成后，指定文件夹的目录如下： 本地部署完成初始化后，执行下列命令，即可生成默认的静态页面。 该命令也可以简写为： 完成生成过后即可执行下列命令，在本地开启服务。 或是简写为： 如果遇到因为在此系统上禁止运行脚本报错，通过管理员权限运行power shell，然后输入命令：set-ExecutionPolicy RemoteSigned 此时命令行窗口应有如下输出： 打开浏览器输入地址  即可看到初始的博客页面。"},{"title":"关于我","date":"2022-12-18T10:49:17.000Z","url":"/about/index.html","categories":[[" ",""]],"content":" 你好，我是 Ryougi，一个学习者。在这里记录分享一些关于学习的内容。 👨‍🎓 教育经历 2016 - 2020：本科毕业于 中国科学技术大学 电子科学与技术系 2020 - 2022：于 中国科学技术大学 电子科学与技术系 攻读硕士学位 2022 至今：硕转博，现于 中国科学技术大学 信息与通信工程系 攻读博士学位 🛠️ 项目经历 2018：2018 MCM&#x2F;ICM（美国大学生数学建模竞赛）Meritorious Winner 2018：USTC 第18届 Robogame 机器人大赛一等奖，负责队伍机器人电路设计与底层控制程序编写。 2020：完成本科毕设《柔性高密度手部压力数据采集系统的设计》。 2022：完成 ”多模态机器人抓取动作数据采集系统的设计与搭建“。 📱 联系方式 ✉️ E-mail：@Ryougi "},{"title":"categories","date":"2022-12-18T10:38:02.000Z","url":"/categories/index.html","categories":[[" ",""]]},{"title":"search","date":"2022-12-26T07:53:38.000Z","url":"/search/index.html","categories":[[" ",""]]},{"title":"tags","date":"2022-12-18T10:37:21.000Z","url":"/tags/index.html","categories":[[" ",""]]}]